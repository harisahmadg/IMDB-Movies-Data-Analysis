{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Data Analysis - Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the new data loading system for IMDB analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import IMDBDataLoader, create_ml_dataset, load_ratings, load_basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = IMDBDataLoader()\n",
    "\n",
    "# Get overview of available datasets\n",
    "datasets = loader.get_available_datasets()\n",
    "print(\"Available datasets:\")\n",
    "for dataset in datasets:\n",
    "    print(f\"  - {dataset}\")\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(\"-\" * 50)\n",
    "info = loader.get_dataset_info()\n",
    "for dataset, details in info.items():\n",
    "    print(f\"{dataset}:\")\n",
    "    print(f\"  Chunks: {details['chunks']}\")\n",
    "    print(f\"  Total rows: {details['total_rows']:,}\")\n",
    "    print(f\"  Sample available: {details['sample_available']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Exploration with Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample datasets for quick exploration\n",
    "ratings_sample = loader.load_sample('title.ratings')\n",
    "basics_sample = loader.load_sample('title.basics')\n",
    "\n",
    "print(\"Ratings sample:\")\n",
    "print(ratings_sample.head())\n",
    "print(f\"Shape: {ratings_sample.shape}\")\n",
    "\n",
    "print(\"\\nBasics sample:\")\n",
    "print(basics_sample.head())\n",
    "print(f\"Shape: {basics_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Larger Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific number of chunks for analysis\n",
    "ratings_medium = loader.load_chunks('title.ratings', max_chunks=3)\n",
    "print(f\"Loaded ratings dataset: {ratings_medium.shape}\")\n",
    "print(f\"Rating distribution:\")\n",
    "print(ratings_medium['averageRating'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ML-Ready Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset ready for machine learning\n",
    "ml_data = create_ml_dataset(sample_size=25000, random_state=42)\n",
    "\n",
    "print(f\"ML dataset shape: {ml_data.shape}\")\n",
    "print(f\"ML dataset columns: {list(ml_data.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(ml_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some quick visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Rating distribution\n",
    "axes[0,0].hist(ml_data['averageRating'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0,0].set_title('Rating Distribution')\n",
    "axes[0,0].set_xlabel('Average Rating')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Votes vs Rating scatter\n",
    "sample_for_scatter = ml_data.sample(5000)  # Use sample for cleaner plot\n",
    "axes[0,1].scatter(sample_for_scatter['averageRating'], sample_for_scatter['numVotes'], alpha=0.6)\n",
    "axes[0,1].set_title('Votes vs Rating')\n",
    "axes[0,1].set_xlabel('Average Rating')\n",
    "axes[0,1].set_ylabel('Number of Votes')\n",
    "axes[0,1].set_yscale('log')\n",
    "\n",
    "# Title types\n",
    "title_counts = ml_data['titleType'].value_counts().head(10)\n",
    "axes[1,0].bar(range(len(title_counts)), title_counts.values)\n",
    "axes[1,0].set_title('Top Title Types')\n",
    "axes[1,0].set_xlabel('Title Type')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].set_xticks(range(len(title_counts)))\n",
    "axes[1,0].set_xticklabels(title_counts.index, rotation=45)\n",
    "\n",
    "# Runtime distribution (where available)\n",
    "runtime_data = ml_data['runtimeMinutes'].dropna()\n",
    "runtime_data = runtime_data[runtime_data < 300]  # Filter extreme outliers\n",
    "axes[1,1].hist(runtime_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1,1].set_title('Runtime Distribution')\n",
    "axes[1,1].set_xlabel('Runtime (minutes)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"IMDB DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTotal records in ML dataset: {len(ml_data):,}\")\n",
    "print(f\"Average rating: {ml_data['averageRating'].mean():.2f}\")\n",
    "print(f\"Median rating: {ml_data['averageRating'].median():.2f}\")\n",
    "print(f\"Rating range: {ml_data['averageRating'].min():.1f} - {ml_data['averageRating'].max():.1f}\")\n",
    "\n",
    "print(f\"\\nTotal votes: {ml_data['numVotes'].sum():,}\")\n",
    "print(f\"Average votes per title: {ml_data['numVotes'].mean():.0f}\")\n",
    "print(f\"Median votes per title: {ml_data['numVotes'].median():.0f}\")\n",
    "\n",
    "print(f\"\\nTop 5 Title Types:\")\n",
    "top_types = ml_data['titleType'].value_counts().head(5)\n",
    "for title_type, count in top_types.items():\n",
    "    print(f\"  {title_type}: {count:,} ({count/len(ml_data)*100:.1f}%)\")\n",
    "\n",
    "# Year range\n",
    "years = ml_data['startYear'].dropna()\n",
    "if len(years) > 0:\n",
    "    print(f\"\\nYear range: {int(years.min())} - {int(years.max())}\")\n",
    "    print(f\"Most common decade: {int(years.mode().iloc[0]//10*10)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrates the basic usage of the new data loading system. You can now:\n",
    "\n",
    "1. **Use the other analysis notebooks** with the updated data loading system\n",
    "2. **Load larger datasets** by adjusting `max_chunks` parameter\n",
    "3. **Create custom datasets** by merging multiple tables\n",
    "4. **Build machine learning models** using the `create_ml_dataset()` function\n",
    "\n",
    "Key functions to remember:\n",
    "- `loader.load_sample(dataset_name)` - Quick samples for exploration\n",
    "- `loader.load_chunks(dataset_name, max_chunks=N)` - Load N chunks of data\n",
    "- `create_ml_dataset(sample_size=N)` - Ready-to-use ML dataset\n",
    "- `loader.create_merged_dataset([datasets], join_column)` - Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}